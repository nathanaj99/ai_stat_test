{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Generating test split: 100%|██████████| 178/178 [00:00<00:00, 58795.57 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "ds = load_dataset(\"lukaemon/bbh\", \"snarks\")\n",
    "data = ds['test'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_question(text):\n",
    "    \"\"\"\n",
    "    Extract the question part between the prompt and options.\n",
    "    Assumes the question starts after the first newline and ends before \"Options:\"\n",
    "    \"\"\"\n",
    "    # Split by newlines and remove the first line (the prompt)\n",
    "    parts = text.split('\\n', 1)\n",
    "    if len(parts) < 2:\n",
    "        return None\n",
    "    \n",
    "    # Take everything after the first line and before \"Options:\"\n",
    "    question_part = parts[1].split('Options:', 1)[0]\n",
    "    \n",
    "    # Clean up any extra whitespace\n",
    "    question_part = question_part.strip()\n",
    "    \n",
    "    return question_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['question'] = data['input'].apply(extract_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = pd.read_csv('../Multi-Prompt-LLM-Evaluation/data/automatic paraphrases/BBH/causal_judgement.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_template(template):\n",
    "    \"\"\"\n",
    "    Ensure 'words' and 'category' are surrounded by curly brackets in the template.\n",
    "    Handles cases where they might already be bracketed or not.\n",
    "    \"\"\"\n",
    "    # First remove any existing brackets around words/category\n",
    "    # This prevents double bracketing\n",
    "    template = re.sub(r'\\{question\\}', 'question', template)\n",
    "    \n",
    "    # Then add brackets around standalone 'words' and 'category'\n",
    "    # Using word boundaries (\\b) to ensure we match whole words only\n",
    "    template = re.sub(r'\\bquestion\\b', '{question}', template)\n",
    "    \n",
    "    return template\n",
    "\n",
    "templates['prompt template'] = templates['prompt template'].apply(standardize_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['question_length'] = data['question'].apply(len)\n",
    "data = data[data['question_length'] < 1100]\n",
    "data = data.drop(columns=['question_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146/146 [00:14<00:00, 10.16it/s]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "\n",
    "df = pd.DataFrame(columns=['question_id', 'perturbation_id', 'prompt', 'correct_answer'])\n",
    "\n",
    "for idx, row in tqdm(data.iterrows(), total=len(data)):\n",
    "    templates_buffer = templates.sample(frac=1, random_state=rng)\n",
    "    for index, row1 in templates_buffer.iterrows():\n",
    "        template = row1['prompt template']\n",
    "        formatted = template.format(question=row['question'])\n",
    "\n",
    "        df.loc[len(df)] = [idx, index, formatted, row['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prompt'] = df['prompt'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/causal_judgement_perturbations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['question'])\n",
    "data = data.rename(columns={'input': 'prompt', 'target': 'correct_answer'})\n",
    "data['question_id'] = data.index\n",
    "data = data[['question_id', 'prompt', 'correct_answer']]\n",
    "data.to_csv('data/causal_judgement_original.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df.groupby('question_id').head(20)\n",
    "filtered_df.to_csv('data/causal_judgement_20.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"lukaemon/bbh\", \"movie_recommendation\")\n",
    "data = ds['test'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = pd.read_csv('../Multi-Prompt-LLM-Evaluation/data/automatic paraphrases/BBH/movie_recommendation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in templates.iterrows():\n",
    "    if '{options}' not in row['prompt template']:\n",
    "        print(row['prompt template'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_template_detailed(text):\n",
    "    \"\"\"\n",
    "    Extract movie list and options from the template.\n",
    "    Returns tuple of (movies_list, options_list) where movies_list is split into individual movies\n",
    "    \"\"\"\n",
    "    # Extract movie list\n",
    "    movie_match = re.search(r'Find a movie similar to (.*?):\\n', text)\n",
    "    movie_list = movie_match.group(1) if movie_match else \"\"\n",
    "    \n",
    "    # Split movie list into individual movies and clean up whitespace\n",
    "    movies = [movie.strip() for movie in movie_list.split(',')]\n",
    "    \n",
    "    # Extract options\n",
    "    options = re.findall(r'\\([A-D]\\) (.*?)(?=\\n|$)', text)\n",
    "    \n",
    "    return movies, options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['movies'] = data['input'].apply(lambda x: parse_template_detailed(x)[0])\n",
    "data['options'] = data['input'].apply(lambda x: parse_template_detailed(x)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_with_tracking(options, original_index):\n",
    "    \"\"\"\n",
    "    Shuffle options while tracking where the item at original_index ends up\n",
    "    \n",
    "    Args:\n",
    "        options: List of options\n",
    "        original_index: The index to track through the shuffle\n",
    "    \n",
    "    Returns:\n",
    "        shuffled_options: List of shuffled options\n",
    "        new_index: New index of the tracked item after shuffling\n",
    "    \"\"\"\n",
    "    # Get permutation indices\n",
    "    rng = np.random.default_rng()\n",
    "    perm = rng.permutation(len(options))\n",
    "    \n",
    "    # Shuffle the options\n",
    "    shuffled_options = [options[i] for i in perm]\n",
    "    \n",
    "    # Find where the original index ended up\n",
    "    new_index = np.where(perm == original_index)[0][0]\n",
    "    \n",
    "    return shuffled_options, new_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Can you recommend a movie that is similar to The Shawshank Redemption, Terminator 2 Judgment Day, Schindler's List, The Lion King?\n",
      "Please choose from the following (A) The Red Turtle\n",
      "(B) Tarzan\n",
      "(C) Aladdin\n",
      "(D) Nothing But Trouble:\n",
      "(A) The Red Turtle\n",
      "(B) Tarzan\n",
      "(C) Aladdin\n",
      "(D) Nothing But Trouble\n"
     ]
    }
   ],
   "source": [
    "print(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:28<00:00,  8.71it/s]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "\n",
    "df = pd.DataFrame(columns=['question_id', 'perturbation_id', 'prompt', 'correct_answer'])\n",
    "target_indices = {'(A)': 0, '(B)': 1, '(C)': 2, '(D)': 3}\n",
    "inv_target_indices = {0: '(A)', 1: '(B)', 2: '(C)', 3: '(D)'}\n",
    "for idx, row in tqdm(data.iterrows(), total=len(data)):\n",
    "    if row['target'] not in target_indices.keys():\n",
    "        continue\n",
    "    target_index = target_indices[row['target']]\n",
    "\n",
    "    templates_buffer = templates.sample(frac=1, random_state=rng)\n",
    "    for index, row1 in templates_buffer.iterrows():\n",
    "\n",
    "        template = row1['prompt template']\n",
    "        movie_list = list(rng.permutation(row['movies']))\n",
    "        # print(row['target'], row['options'])\n",
    "        options, new_index = shuffle_with_tracking(row['options'], target_index)\n",
    "\n",
    "        # print(new_index, options)\n",
    "        movie_list_str = ', '.join(movie_list)\n",
    "\n",
    "        options_str = '\\n'.join([f'({chr(65 + i)}) {option}' for i, option in enumerate(options)])\n",
    "        formatted = template.format(movie_list=movie_list_str, options=options_str)\n",
    "\n",
    "        df.loc[len(df)] = [idx, index, formatted, inv_target_indices[new_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prompt'] = df['prompt'].apply(lambda x: x.strip())\n",
    "df.to_csv('data/movie_recommendation_perturbations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['movies', 'options'])\n",
    "data = data.rename(columns={'input': 'prompt', 'target': 'correct_answer'})\n",
    "data['question_id'] = data.index\n",
    "data = data[['question_id', 'prompt', 'correct_answer']]\n",
    "data.to_csv('data/movie_recommendation_original.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df.groupby('question_id').head(20)\n",
    "filtered_df.to_csv('data/movie_recommendation_20.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "ds = load_dataset(\"lukaemon/bbh\", \"snarks\")\n",
    "data = ds['test'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_question(text):\n",
    "    \"\"\"\n",
    "    Extract the question part between the prompt and options.\n",
    "    Assumes the question starts after the first newline and ends before \"Options:\"\n",
    "    \"\"\"\n",
    "    # Split by newlines and remove the first line (the prompt)\n",
    "    options = text.split('Options:')[1].strip()\n",
    "    options = re.findall(r'\\([A-D]\\) (.*?)(?=\\n|$)', options)\n",
    "    \n",
    "    return options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['options'] = data['input'].apply(extract_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = pd.read_csv('raw_data/perturbations/snarks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = templates[~(templates['prompt template'].str.contains('{question}') | templates['prompt template'].str.contains('{prompt}'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_with_tracking(options, original_index, rng):\n",
    "    \"\"\"\n",
    "    Shuffle options while tracking where the item at original_index ends up\n",
    "    \n",
    "    Args:\n",
    "        options: List of options\n",
    "        original_index: The index to track through the shuffle\n",
    "    \n",
    "    Returns:\n",
    "        shuffled_options: List of shuffled options\n",
    "        new_index: New index of the tracked item after shuffling\n",
    "    \"\"\"\n",
    "    # Get permutation indices\n",
    "    perm = rng.permutation(len(options))\n",
    "    \n",
    "    # Shuffle the options\n",
    "    shuffled_options = [options[i] for i in perm]\n",
    "    \n",
    "    # Find where the original index ended up\n",
    "    new_index = np.where(perm == original_index)[0][0]\n",
    "    return shuffled_options, new_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 178/178 [00:46<00:00,  3.81it/s]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "\n",
    "df = pd.DataFrame(columns=['question_id', 'perturbation_id', 'prompt', 'correct_answer'])\n",
    "target_indices = {'(A)': 0, '(B)': 1}\n",
    "inv_target_indices = {0: '(A)', 1: '(B)'}\n",
    "for idx, row in tqdm(data.iterrows(), total=len(data)):\n",
    "    if row['target'] not in target_indices.keys():\n",
    "        continue\n",
    "    target_index = target_indices[row['target']]\n",
    "\n",
    "    templates_buffer = templates.sample(frac=1, random_state=rng)\n",
    "    df_buffer = pd.DataFrame(columns=['question_id', 'perturbation_id', 'prompt', 'correct_answer'])\n",
    "    for index, row1 in templates_buffer.iterrows():\n",
    "\n",
    "        template = row1['prompt template']\n",
    "        # print(row['target'], row['options'])\n",
    "        options, new_index = shuffle_with_tracking(row['options'], target_index, rng)\n",
    "        # print(options, new_index)\n",
    "\n",
    "        options_str = '\\n'.join([f'({chr(65 + i)}) {option}' for i, option in enumerate(options)])\n",
    "        # print(template)\n",
    "        formatted = template.format(options=options_str)\n",
    "        # print(formatted)\n",
    "\n",
    "        df_buffer.loc[len(df_buffer)] = [idx, index, formatted, inv_target_indices[new_index]]\n",
    "    df = pd.concat([df, df_buffer], ignore_index=True)\n",
    "# df['prompt'] = df['prompt'].apply(lambda x: x.strip())\n",
    "# df.to_csv('data/snarks_perturbations.csv', index=False)\n",
    "# data = data.drop(columns=['options'])\n",
    "# data = data.rename(columns={'input': 'prompt', 'target': 'correct_answer'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prompt'] = df['prompt'].apply(lambda x: x.strip())\n",
    "df.to_csv('data/snarks/perturbations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['options'])\n",
    "data = data.rename(columns={'input': 'prompt', 'target': 'correct_answer'})\n",
    "data['question_id'] = data.index\n",
    "data = data[['question_id', 'prompt', 'correct_answer']]\n",
    "data.to_csv('data/snarks/original.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     question_id                                             prompt  \\\n",
      "0              0  Which statement is sarcastic?\\nOptions:\\n(A) H...   \n",
      "1              1  Which statement is sarcastic?\\nOptions:\\n(A) H...   \n",
      "2              2  Which statement is sarcastic?\\nOptions:\\n(A) J...   \n",
      "3              3  Which statement is sarcastic?\\nOptions:\\n(A) Y...   \n",
      "4              4  Which statement is sarcastic?\\nOptions:\\n(A) H...   \n",
      "..           ...                                                ...   \n",
      "173          173  Which statement is sarcastic?\\nOptions:\\n(A) I...   \n",
      "174          174  Which statement is sarcastic?\\nOptions:\\n(A) Q...   \n",
      "175          175  Which statement is sarcastic?\\nOptions:\\n(A) W...   \n",
      "176          176  Which statement is sarcastic?\\nOptions:\\n(A) G...   \n",
      "177          177  Which statement is sarcastic?\\nOptions:\\n(A) W...   \n",
      "\n",
      "    correct_answer  \n",
      "0              (B)  \n",
      "1              (A)  \n",
      "2              (A)  \n",
      "3              (B)  \n",
      "4              (A)  \n",
      "..             ...  \n",
      "173            (B)  \n",
      "174            (A)  \n",
      "175            (A)  \n",
      "176            (A)  \n",
      "177            (A)  \n",
      "\n",
      "[178 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/snarks/original.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df.groupby('question_id').head(20)\n",
    "filtered_df.to_csv('data/snarks/20.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formal Fallacies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "ds = load_dataset(\"lukaemon/bbh\", \"formal_fallacies\")\n",
    "data = ds['test'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['question'] = data['input'].apply(lambda x: x.split('\\\"')[1].strip())\n",
    "data['question'] = data['question'].apply(lambda x: f\"\\\"{x}\\\"\")\n",
    "data = data[data['question'].str.len() < 600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = pd.read_csv('raw_data/perturbations/formal_fallacies.csv')\n",
    "templates = templates[templates['correct'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:53<00:00,  4.36it/s]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "\n",
    "df = pd.DataFrame(columns=['question_id', 'perturbation_id', 'prompt', 'correct_answer'])\n",
    "\n",
    "for idx, row in tqdm(data.iterrows(), total=len(data)):\n",
    "    templates_buffer = templates.sample(frac=1, random_state=rng)\n",
    "    df_buffer = pd.DataFrame(columns=['question_id', 'perturbation_id', 'prompt', 'correct_answer'])\n",
    "    for index, row1 in templates_buffer.iterrows():\n",
    "        template = row1['prompt template']\n",
    "        formatted = template.format(input=row['question'])\n",
    "\n",
    "        df_buffer.loc[len(df_buffer)] = [idx, index, formatted, row['target']]\n",
    "    df = pd.concat([df, df_buffer], ignore_index=True)\n",
    "df['prompt'] = df['prompt'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prompt'] = df['prompt'].apply(lambda x: x.strip())\n",
    "df.to_csv('data/formal_fallacies/perturbations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['question', 'length'])\n",
    "data = data.rename(columns={'input': 'prompt', 'target': 'correct_answer'})\n",
    "data['question_id'] = data.index\n",
    "data = data[['question_id', 'prompt', 'correct_answer']]\n",
    "data.to_csv('data/formal_fallacies/original.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df.groupby('question_id').head(20)\n",
    "filtered_df.to_csv('data/formal_fallacies/20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## taking 5 perturbations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/movie_recommendation/20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>perturbation_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>correct_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>Q: Can you recommend a movie similar to The Ma...</td>\n",
       "      <td>(C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>Q: Can you recommend a movie similar to the fo...</td>\n",
       "      <td>(B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>Given a list of movies, recommend a movie that...</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>I need your help to find movies that are simil...</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>Based on your movie preferences, we can recomm...</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4815</th>\n",
       "      <td>249</td>\n",
       "      <td>95</td>\n",
       "      <td>I am looking for a movie that is similar to Te...</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4816</th>\n",
       "      <td>249</td>\n",
       "      <td>157</td>\n",
       "      <td>Recommend a movie similar to a given list of m...</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4817</th>\n",
       "      <td>249</td>\n",
       "      <td>178</td>\n",
       "      <td>Recommend a movie similar to a given list of m...</td>\n",
       "      <td>(B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4818</th>\n",
       "      <td>249</td>\n",
       "      <td>39</td>\n",
       "      <td>Q: Can you recommend a movie that is similar t...</td>\n",
       "      <td>(D)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4819</th>\n",
       "      <td>249</td>\n",
       "      <td>74</td>\n",
       "      <td>Your task is to find a movie similar to Termin...</td>\n",
       "      <td>(B)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4820 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      question_id  perturbation_id  \\\n",
       "0               0               19   \n",
       "1               0               42   \n",
       "2               0              153   \n",
       "3               0               78   \n",
       "4               0              145   \n",
       "...           ...              ...   \n",
       "4815          249               95   \n",
       "4816          249              157   \n",
       "4817          249              178   \n",
       "4818          249               39   \n",
       "4819          249               74   \n",
       "\n",
       "                                                 prompt correct_answer  \n",
       "0     Q: Can you recommend a movie similar to The Ma...            (C)  \n",
       "1     Q: Can you recommend a movie similar to the fo...            (B)  \n",
       "2     Given a list of movies, recommend a movie that...            (A)  \n",
       "3     I need your help to find movies that are simil...            (A)  \n",
       "4     Based on your movie preferences, we can recomm...            (A)  \n",
       "...                                                 ...            ...  \n",
       "4815  I am looking for a movie that is similar to Te...            (A)  \n",
       "4816  Recommend a movie similar to a given list of m...            (A)  \n",
       "4817  Recommend a movie similar to a given list of m...            (B)  \n",
       "4818  Q: Can you recommend a movie that is similar t...            (D)  \n",
       "4819  Your task is to find a movie similar to Termin...            (B)  \n",
       "\n",
       "[4820 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q: Can you recommend a movie similar to The Mask, Batman, The Fugitive, Pretty Woman?\\nChoose from the following options:\\n(A) Maelstrom\\n(B) Lamerica\\n(C) The Lion King\\n(D) The Front Page\\nA:'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('question_id').head(5).iloc[0]['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('question_id').head(5).to_csv('data/movie_recommendation/5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>perturbation_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>correct_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>Q: Can you recommend a movie similar to The Ma...</td>\n",
       "      <td>(C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>Q: Can you recommend a movie similar to the fo...</td>\n",
       "      <td>(B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>Given a list of movies, recommend a movie that...</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>I need your help to find movies that are simil...</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>Based on your movie preferences, we can recomm...</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4815</th>\n",
       "      <td>249</td>\n",
       "      <td>95</td>\n",
       "      <td>I am looking for a movie that is similar to Te...</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4816</th>\n",
       "      <td>249</td>\n",
       "      <td>157</td>\n",
       "      <td>Recommend a movie similar to a given list of m...</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4817</th>\n",
       "      <td>249</td>\n",
       "      <td>178</td>\n",
       "      <td>Recommend a movie similar to a given list of m...</td>\n",
       "      <td>(B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4818</th>\n",
       "      <td>249</td>\n",
       "      <td>39</td>\n",
       "      <td>Q: Can you recommend a movie that is similar t...</td>\n",
       "      <td>(D)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4819</th>\n",
       "      <td>249</td>\n",
       "      <td>74</td>\n",
       "      <td>Your task is to find a movie similar to Termin...</td>\n",
       "      <td>(B)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4820 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      question_id  perturbation_id  \\\n",
       "0               0               19   \n",
       "1               0               42   \n",
       "2               0              153   \n",
       "3               0               78   \n",
       "4               0              145   \n",
       "...           ...              ...   \n",
       "4815          249               95   \n",
       "4816          249              157   \n",
       "4817          249              178   \n",
       "4818          249               39   \n",
       "4819          249               74   \n",
       "\n",
       "                                                 prompt correct_answer  \n",
       "0     Q: Can you recommend a movie similar to The Ma...            (C)  \n",
       "1     Q: Can you recommend a movie similar to the fo...            (B)  \n",
       "2     Given a list of movies, recommend a movie that...            (A)  \n",
       "3     I need your help to find movies that are simil...            (A)  \n",
       "4     Based on your movie preferences, we can recomm...            (A)  \n",
       "...                                                 ...            ...  \n",
       "4815  I am looking for a movie that is similar to Te...            (A)  \n",
       "4816  Recommend a movie similar to a given list of m...            (A)  \n",
       "4817  Recommend a movie similar to a given list of m...            (B)  \n",
       "4818  Q: Can you recommend a movie that is similar t...            (D)  \n",
       "4819  Your task is to find a movie similar to Termin...            (B)  \n",
       "\n",
       "[4820 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
